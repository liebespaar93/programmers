{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Plot multinomial and One-vs-Rest Logistic Regression\n",
        "\n",
        "Plot decision surface of multinomial and One-vs-Rest Logistic Regression.\n",
        "The hyperplanes corresponding to the three One-vs-Rest (OVR) classifiers\n",
        "are represented by the dashed lines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n",
        "# Authors: Tom Dupre la Tour <tom.dupre-la-tour@m4x.org>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# make 3-class dataset for classification\n",
        "centers = [[-5, 0], [0, 1.5], [5, -1]]\n",
        "X, y = make_blobs(n_samples=1000, centers=centers, random_state=40)\n",
        "transformation = [[0.4, 0.2], [-0.4, 1.2]]\n",
        "X = np.dot(X, transformation)\n",
        "\n",
        "for multi_class in ('multinomial', 'ovr'):\n",
        "    clf = LogisticRegression(solver='sag', max_iter=100, random_state=42,\n",
        "                             multi_class=multi_class).fit(X, y)\n",
        "\n",
        "    # print the training scores\n",
        "    print(\"training score : %.3f (%s)\" % (clf.score(X, y), multi_class))\n",
        "\n",
        "    # create a mesh to plot in\n",
        "    h = .02  # step size in the mesh\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    # Put the result into a color plot\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.figure()\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "    plt.title(\"Decision surface of LogisticRegression (%s)\" % multi_class)\n",
        "    plt.axis('tight')\n",
        "\n",
        "    # Plot also the training points\n",
        "    colors = \"bry\"\n",
        "    for i, color in zip(clf.classes_, colors):\n",
        "        idx = np.where(y == i)\n",
        "        plt.scatter(X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired,\n",
        "                    edgecolor='black', s=20)\n",
        "\n",
        "    # Plot the three one-against-all classifiers\n",
        "    xmin, xmax = plt.xlim()\n",
        "    ymin, ymax = plt.ylim()\n",
        "    coef = clf.coef_\n",
        "    intercept = clf.intercept_\n",
        "\n",
        "    def plot_hyperplane(c, color):\n",
        "        def line(x0):\n",
        "            return (-(x0 * coef[c, 0]) - intercept[c]) / coef[c, 1]\n",
        "        plt.plot([xmin, xmax], [line(xmin), line(xmax)],\n",
        "                 ls=\"--\", color=color)\n",
        "\n",
        "    for i, color in zip(clf.classes_, colors):\n",
        "        plot_hyperplane(i, color)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def makeline(linedata):\n",
        "    xb = 0\n",
        "    yb = 0\n",
        "    mlist = []\n",
        "    for i in linedata:\n",
        "        x11 = i[0][0]\n",
        "        x12 = i[0][1]\n",
        "        y11 = i[1][0]\n",
        "        y12 = i[1][1]\n",
        "        m = (y12-y11)/(x12-x11)\n",
        "        mlist.append([m,x11,y11])\n",
        "\n",
        "    dot_line  = []\n",
        "    for k in range(3):\n",
        "        if k == 2 :\n",
        "            i = -1\n",
        "        else:\n",
        "            i = k\n",
        "        xy = (mlist[i][0]*mlist[i][1] -mlist[i][2] -mlist[i+1][0]*mlist[i+1][1] +mlist[i+1][2])/(mlist[i][0] - mlist[i+1][0])\n",
        "        yx = mlist[i][0]*(xy - mlist[i][1]) + mlist[i][2]\n",
        "        print(xy, yx)\n",
        "        dot_line.append([xy,yx])\n",
        "        \n",
        "\n",
        "    sum_x = 0\n",
        "    sum_y = 0\n",
        "    for i in dot_line:\n",
        "        sum_x += i[0]\n",
        "        sum_y += i[1]\n",
        "    print(sum_x/3,sum_y/3)\n",
        "    xs = sum_x/3\n",
        "    ys = sum_y/3\n",
        "    \n",
        "    minmaxlist = []\n",
        "    for i in range(3):\n",
        "        m1 = (dot_line[i][1]-ys )/(dot_line[i][0]-xs)\n",
        "        if xs > dot_line[i][0] :\n",
        "            minmaxlist.append([xmin,m1*xmin])\n",
        "        else:\n",
        "            minmaxlist.append([xmax,m1*xmax-ys])\n",
        "    return xs, ys, minmaxlist\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(__doc__)\n",
        "# Authors: Tom Dupre la Tour <tom.dupre-la-tour@m4x.org>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# make 3-class dataset for classification\n",
        "centers = [[-5, 0], [0, 1.5], [5, -1]]\n",
        "X, y = make_blobs(n_samples=1000, centers=centers, random_state=40)\n",
        "transformation = [[0.4, 0.2], [-0.4, 1.2]]\n",
        "X = np.dot(X, transformation)\n",
        "\n",
        "\n",
        "multi_class ='ovr'\n",
        "\n",
        "clf = LogisticRegression(solver='sag', max_iter=100, random_state=42, multi_class=multi_class).fit(X, y)\n",
        "\n",
        "# print the training scores\n",
        "print(\"training score : %.3f (%s)\" % (clf.score(X, y), multi_class))\n",
        "\n",
        "# create a mesh to plot in\n",
        "h = .02  # step size in the mesh\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                        np.arange(y_min, y_max, h))\n",
        "\n",
        "# Plot the decision boundary. For that, we will assign a color to each\n",
        "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure()\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "plt.title(\"Decision surface of LogisticRegression (%s)\" % multi_class)\n",
        "plt.axis('tight')\n",
        "\n",
        "# Plot also the training points\n",
        "colors = \"bry\"\n",
        "for i, color in zip(clf.classes_, colors):\n",
        "    idx = np.where(y == i)\n",
        "    plt.scatter(X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired,\n",
        "                edgecolor='black', s=20)\n",
        "\n",
        "# Plot the three one-against-all classifiers\n",
        "xmin, xmax = plt.xlim()\n",
        "ymin, ymax = plt.ylim()\n",
        "coef = clf.coef_\n",
        "intercept = clf.intercept_\n",
        "\n",
        "linedata = []\n",
        "def plot_hyperplane(c, color):\n",
        "    def line(x0):\n",
        "        return (-(x0 * coef[c, 0]) - intercept[c]) / coef[c, 1]\n",
        "    plt.plot([xmin, xmax], [line(xmin), line(xmax)],\n",
        "                ls=\"--\", color=color)\n",
        "    linedata.append([[xmin, xmax], [line(xmin), line(xmax)]])\n",
        "\n",
        "for i, color in zip(clf.classes_, colors):\n",
        "    plot_hyperplane(i, color)\n",
        "\n",
        "xs, ys, minmaxlist = makeline(linedata)\n",
        "\n",
        "for i in minmaxlist:\n",
        "    plt.plot([xs,i[0]],[ys,i[1]],color='#ffffff')\n",
        "print(linedata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xb = 0\n",
        "yb = 0\n",
        "mlist = []\n",
        "for i in linedata:\n",
        "    x11 = i[0][0]\n",
        "    x12 = i[0][1]\n",
        "    y11 = i[1][0]\n",
        "    y12 = i[1][1]\n",
        "    m = (y12-y11)/(x12-x11)\n",
        "    mlist.append([m,x11,y11])\n",
        "\n",
        "dot_line  = []\n",
        "for k in range(3):\n",
        "    if k == 2 :\n",
        "        i = -1\n",
        "    else:\n",
        "        i = k\n",
        "    xy = (mlist[i][0]*mlist[i][1] -mlist[i][2] -mlist[i+1][0]*mlist[i+1][1] +mlist[i+1][2])/(mlist[i][0] - mlist[i+1][0])\n",
        "    yx = mlist[i][0]*(xy - mlist[i][1]) + mlist[i][2]\n",
        "    print(xy, yx)\n",
        "    dot_line.append([xy,yx])\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum_x = 0\n",
        "sum_y = 0\n",
        "for i in dot_line:\n",
        "    sum_x += i[0]\n",
        "    sum_y += i[1]\n",
        "print(sum_x/3,sum_y/3)\n",
        "xs = sum_x/3\n",
        "ys = sum_y/3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m1 = (dot_line[0][1]-ys )/(dot_line[0][0]-xs)\n",
        "m1*xmin-ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "minmaxlist = []\n",
        "for i in range(3):\n",
        "    m1 = (dot_line[i][1]-ys )/(dot_line[i][0]-xs)\n",
        "    if xs > dot_line[i][0] :\n",
        "        minmaxlist.append([xmin,m1*xmin-ys])\n",
        "    else:\n",
        "        minmaxlist.append([xmax,m1*xmax-ys])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "minmaxlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comnpute_cost(X, t,w):\n",
        "    N = len(t)\n",
        "    h = sigmoid(X @ w)\n",
        "    epsilon = 1e-5\n",
        "    cost = (1/N)*(((-t).T @ np.log(h+ epsilon)) -((1-t).T @np.log(1-h + epsilon)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(__doc__)\n",
        "# Authors: Tom Dupre la Tour <tom.dupre-la-tour@m4x.org>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# make 3-class dataset for classification\n",
        "centers = [[-5, 0], [0, 1.5], [5, -1]]\n",
        "X, y = make_blobs(n_samples=1000, centers=centers, random_state=40)\n",
        "transformation = [[0.4, 0.2], [-0.4, 1.2]]\n",
        "X = np.dot(X, transformation)\n",
        "\n",
        "multi_class = 'multinomial'\n",
        "clf = LogisticRegression(solver='sag', max_iter=100, random_state=42,\n",
        "                            multi_class=multi_class).fit(X, y)\n",
        "\n",
        "# print the training scores\n",
        "print(\"training score : %.3f (%s)\" % (clf.score(X, y), multi_class))\n",
        "\n",
        "# create a mesh to plot in\n",
        "h = .02  # step size in the mesh\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                        np.arange(y_min, y_max, h))\n",
        "\n",
        "# Plot the decision boundary. For that, we will assign a color to each\n",
        "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure()\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "plt.title(\"Decision surface of LogisticRegression (%s)\" % multi_class)\n",
        "plt.axis('tight')\n",
        "tick1 = len(set(Z[0]))\n",
        "tootoo = 1\n",
        "for num, i in enumerate(Z):\n",
        "    tick2 = len(set(i))\n",
        "    if tick1 != tick2 and tootoo == 1:\n",
        "            \n",
        "        tootoo = 0\n",
        "        if tick2 == 3 :\n",
        "            center=num\n",
        "        else:\n",
        "            center=num-1\n",
        "        print(num, tick1, tick2)\n",
        "\n",
        "for i in set(Z[center]):\n",
        "    if i not in Z[center-1] or i not in Z[center+1]:\n",
        "        middle_key = i\n",
        "        print(i) \n",
        "\n",
        "for num, i in enumerate(Z[center]):\n",
        "    if middle_key == i :\n",
        "        center2 = num\n",
        "        print(num)\n",
        "xx[center,center2], yy[center,center2]\n",
        "temp = 99\n",
        "transe = []\n",
        "for num, i in enumerate(Z[-1]):\n",
        "    if temp != i :\n",
        "        temp = i \n",
        "        transe.append(num)\n",
        "        print(num)\n",
        "\n",
        "for i in range(len(set(Z[-1]))-1):\n",
        "    temp=transe.pop()\n",
        "    plt.plot([xx[center,center2],xx[-1,temp]],[yy[center,center2], yy[-1,temp]],color='#ffffff')\n",
        "\n",
        "    temp = 99\n",
        "transe = []\n",
        "real = []\n",
        "for num, i in enumerate(Z[0]):\n",
        "    if temp != i :\n",
        "        temp = i \n",
        "        transe.append(num)\n",
        "        print(num)\n",
        "\n",
        "for i in range(len(set(Z[0]))-1):\n",
        "    temp=transe.pop()\n",
        "    plt.plot([xx[center,center2],xx[0,temp]],[yy[center,center2], yy[0,temp]],color='#ffffff')\n",
        "\n",
        "    # Plot also the training points\n",
        "    colors = \"bry\"\n",
        "    for i, color in zip(clf.classes_, colors):\n",
        "        idx = np.where(y == i)\n",
        "        plt.scatter(X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired,\n",
        "                    edgecolor='black', s=20)\n",
        "\n",
        "    # Plot the three one-against-all classifiers\n",
        "    xmin, xmax = plt.xlim()\n",
        "    ymin, ymax = plt.ylim()\n",
        "    coef = clf.coef_\n",
        "    intercept = clf.intercept_\n",
        "\n",
        "    def plot_hyperplane(c, color):\n",
        "        def line(x0):\n",
        "            return (-(x0 * coef[c, 0]) - intercept[c]) / coef[c, 1]\n",
        "        plt.plot([xmin, xmax], [line(xmin), line(xmax)],\n",
        "                 ls=\"--\", color=color)\n",
        "\n",
        "    for i, color in zip(clf.classes_, colors):\n",
        "        plot_hyperplane(i, color)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                        np.arange(y_min, y_max, h))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plt.plot([xx[center,center2],xx[-1,267]],[yy[center,center2], yy[-1,267]],color='#ffffff')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xx[center,center2], yy[center,center2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xx[-1,267], yy[-1,267]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.tri as tri\n",
        "import numpy as np\n",
        "npts = 100\n",
        "x = np.random.uniform(-2, 2, npts)\n",
        "y = np.random.uniform(-2, 2, npts)\n",
        "z = x * np.exp(-x**2 - y**2)\n",
        "ngridx = 100\n",
        "ngridy = 100\n",
        "xi = np.linspace(-2.2, 2.2, ngridx)\n",
        "yi = np.linspace(-2.2, 2.2, ngridy)\n",
        "triang = tri.Triangulation(x, y)\n",
        "interpolator = tri.LinearTriInterpolator(triang, z)\n",
        "Xi, Yi = np.meshgrid(xi, yi)\n",
        "zi = interpolator(Xi, Yi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#%% import libraries\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "#%% iris dataset\n",
        "\n",
        "iris = sns.load_dataset('iris')\n",
        "\n",
        "iris.info()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "iris.groupby('species').size()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#%% scatter plot by 'species'\n",
        "\n",
        "sns.scatterplot(x='petal_length', \n",
        "\n",
        "                y='petal_width', \n",
        "\n",
        "                hue='species', \n",
        "\n",
        "                style='species', \n",
        "\n",
        "                s=100, \n",
        "\n",
        "                data=iris)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#%% Classification using Random Forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(iris[['petal_length', 'petal_width']])\n",
        "\n",
        "y = iris['species']\n",
        "\n",
        "y = np.where(y=='setosa', 0, np.where(y=='versicolor', 1, 2))\n",
        "\n",
        "\n",
        "\n",
        "rfc = RandomForestClassifier(max_depth=2, n_estimators=200, random_state=1004)\n",
        "\n",
        "rfc.fit(X, y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# create coordinate matrices from x_min~x_max, y_min~y_max coordinates\n",
        "\n",
        "h = 0.01\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
        "\n",
        "y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
        "\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "XY = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "\n",
        "\n",
        "XY.shape\n",
        "\n",
        "\n",
        "# predict\n",
        "\n",
        "pred_cls = rfc.predict(XY)\n",
        "\n",
        "\n",
        "\n",
        "# align the shape of Z with xx\n",
        "\n",
        "Z = pred_cls.reshape(xx.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Random Forest Classifier: Decision Boundary\n",
        "\n",
        "plt.contourf(xx, yy, Z)\n",
        "\n",
        "plt.axis('off')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "XY"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python395jvsc74a57bd07812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d",
      "display_name": "Python 3.9.5 64-bit ('3.9')"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "metadata": {
      "interpreter": {
        "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
      }
    },
    "interpreter": {
      "hash": "e25d969c92605c0c7f415fe0832a23d7af293f208a65b2ef2c6d7f3dcccb9abb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}